{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Data Engineering & Feature Development\n",
    "## Career Recommendation Engine\n",
    "\n",
    "This notebook covers:\n",
    "- Data loading and analysis\n",
    "- Feature engineering\n",
    "- Handling class imbalance\n",
    "- Feature importance analysis\n",
    "- Correlation matrix visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from preprocessing import DataPreprocessor, split_data\n",
    "from feature_engineering import FeatureEngineer\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessor\n",
    "preprocessor = DataPreprocessor('../data/synthetic_user_profiles_large.csv')\n",
    "\n",
    "# Load data\n",
    "df = preprocessor.load_data()\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Dataset Statistics:\")\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"\\nNumerical columns summary:\")\n",
    "df[['analytical', 'creative', 'social', 'experience']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze unique values\n",
    "print(\"Unique Skills:\")\n",
    "unique_skills = preprocessor.get_unique_values('skills')\n",
    "print(f\"Total: {len(unique_skills)}\")\n",
    "print(sorted(unique_skills))\n",
    "\n",
    "print(\"\\nUnique Interests:\")\n",
    "unique_interests = preprocessor.get_unique_values('interests')\n",
    "print(f\"Total: {len(unique_interests)}\")\n",
    "print(sorted(unique_interests))\n",
    "\n",
    "print(\"\\nUnique Careers:\")\n",
    "unique_careers = preprocessor.get_unique_values('target_careers')\n",
    "print(f\"Total: {len(unique_careers)}\")\n",
    "print(sorted(unique_careers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run complete preprocessing pipeline\n",
    "df_processed, y_binary, career_names = preprocessor.get_preprocessed_data()\n",
    "\n",
    "print(\"\\nPreprocessed data shape:\", df_processed.shape)\n",
    "print(\"Target matrix shape:\", y_binary.shape)\n",
    "print(\"Number of careers:\", len(career_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize personality trait distributions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "traits = ['analytical', 'creative', 'social']\n",
    "colors = ['#3498db', '#e74c3c', '#2ecc71']\n",
    "\n",
    "for ax, trait, color in zip(axes, traits, colors):\n",
    "    ax.hist(df[trait], bins=30, color=color, alpha=0.7, edgecolor='black')\n",
    "    ax.set_title(f'{trait.capitalize()} Trait Distribution', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Score')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.axvline(df[trait].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {df[trait].mean():.2f}')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize education and experience distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Education distribution\n",
    "education_counts = df['education'].value_counts()\n",
    "axes[0].bar(education_counts.index, education_counts.values, color='#9b59b6', alpha=0.7)\n",
    "axes[0].set_title('Education Level Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Education Level')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Experience distribution\n",
    "axes[1].hist(df['experience'], bins=20, color='#f39c12', alpha=0.7, edgecolor='black')\n",
    "axes[1].set_title('Work Experience Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Years of Experience')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].axvline(df['experience'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {df['experience'].mean():.1f}')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize feature engineer\n",
    "engineer = FeatureEngineer(df_processed)\n",
    "\n",
    "# Engineer all features\n",
    "df_features, feature_names = engineer.engineer_all_features()\n",
    "\n",
    "print(f\"\\nTotal features created: {len(feature_names)}\")\n",
    "print(f\"Feature matrix shape: {df_features[feature_names].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display feature statistics\n",
    "feature_stats = engineer.get_feature_importance_data(df_features, feature_names)\n",
    "print(\"\\nFeature Statistics:\")\n",
    "feature_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize skill clusters\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Technical vs Soft Skills\n",
    "axes[0, 0].scatter(df_features['technical_skills_count'], df_features['soft_skills_count'], \n",
    "                   alpha=0.5, c='#3498db')\n",
    "axes[0, 0].set_xlabel('Technical Skills Count')\n",
    "axes[0, 0].set_ylabel('Soft Skills Count')\n",
    "axes[0, 0].set_title('Technical vs Soft Skills', fontweight='bold')\n",
    "\n",
    "# Skill diversity distribution\n",
    "axes[0, 1].hist(df_features['skill_diversity'], bins=30, color='#2ecc71', alpha=0.7, edgecolor='black')\n",
    "axes[0, 1].set_xlabel('Skill Diversity Score')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].set_title('Skill Diversity Distribution', fontweight='bold')\n",
    "\n",
    "# Interest breadth\n",
    "interest_counts = df_features['interest_breadth'].value_counts().sort_index()\n",
    "axes[1, 0].bar(interest_counts.index, interest_counts.values, color='#e74c3c', alpha=0.7)\n",
    "axes[1, 0].set_xlabel('Number of Interests')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "axes[1, 0].set_title('Interest Breadth Distribution', fontweight='bold')\n",
    "\n",
    "# Career readiness score\n",
    "axes[1, 1].hist(df_features['career_readiness'], bins=30, color='#9b59b6', alpha=0.7, edgecolor='black')\n",
    "axes[1, 1].set_xlabel('Career Readiness Score')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].set_title('Career Readiness Distribution', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "X = df_features[feature_names]\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "# Visualize correlation matrix\n",
    "plt.figure(figsize=(16, 14))\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Matrix', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find highly correlated features (|correlation| > 0.7)\n",
    "high_corr_pairs = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.7:\n",
    "            high_corr_pairs.append({\n",
    "                'Feature 1': correlation_matrix.columns[i],\n",
    "                'Feature 2': correlation_matrix.columns[j],\n",
    "                'Correlation': correlation_matrix.iloc[i, j]\n",
    "            })\n",
    "\n",
    "if high_corr_pairs:\n",
    "    print(\"Highly Correlated Feature Pairs (|r| > 0.7):\")\n",
    "    pd.DataFrame(high_corr_pairs).sort_values('Correlation', ascending=False)\n",
    "else:\n",
    "    print(\"No highly correlated feature pairs found (|r| > 0.7)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Class Imbalance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze class distribution\n",
    "class_distribution = preprocessor.analyze_class_imbalance(y_binary, career_names)\n",
    "\n",
    "# Visualize class distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(class_distribution['career'], class_distribution['count'], color='#3498db', alpha=0.7)\n",
    "plt.xlabel('Number of Samples', fontsize=12)\n",
    "plt.ylabel('Career', fontsize=12)\n",
    "plt.title('Career Label Distribution (Class Imbalance)', fontsize=14, fontweight='bold')\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nImbalance Ratio: {class_distribution['count'].max() / class_distribution['count'].min():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Importance (Random Forest Based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "# Train a quick Random Forest for feature importance\n",
    "X = df_features[feature_names].values\n",
    "y = y_binary\n",
    "\n",
    "# Quick RF model\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
    "multi_rf = MultiOutputClassifier(rf, n_jobs=-1)\n",
    "\n",
    "print(\"Training Random Forest for feature importance analysis...\")\n",
    "multi_rf.fit(X, y)\n",
    "print(\"âœ“ Training complete\")\n",
    "\n",
    "# Calculate average feature importance across all outputs\n",
    "importances = np.mean([estimator.feature_importances_ for estimator in multi_rf.estimators_], axis=0)\n",
    "\n",
    "# Create feature importance DataFrame\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = feature_importance_df.head(15)\n",
    "plt.barh(top_features['feature'], top_features['importance'], color='#2ecc71', alpha=0.7)\n",
    "plt.xlabel('Feature Importance', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('Top 15 Feature Importance (Random Forest)', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed features and targets for model training\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# Create processed data directory\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "# Save features\n",
    "X_processed = df_features[feature_names]\n",
    "X_processed.to_csv('../data/processed/features.csv', index=False)\n",
    "\n",
    "# Save targets\n",
    "np.save('../data/processed/targets.npy', y_binary)\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    'feature_names': feature_names,\n",
    "    'career_names': career_names,\n",
    "    'n_samples': len(X_processed),\n",
    "    'n_features': len(feature_names),\n",
    "    'n_careers': len(career_names)\n",
    "}\n",
    "joblib.dump(metadata, '../data/processed/metadata.pkl')\n",
    "\n",
    "print(\"âœ“ Processed data saved successfully!\")\n",
    "print(f\"  - Features: {X_processed.shape}\")\n",
    "print(f\"  - Targets: {y_binary.shape}\")\n",
    "print(f\"  - Career names: {len(career_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Dataset**: Successfully loaded and preprocessed user profile data\n",
    "2. **Features**: Engineered 24 meaningful features from raw data\n",
    "3. **Class Imbalance**: Identified imbalance in career labels (will handle in model training)\n",
    "4. **Feature Importance**: Identified top contributing features for career prediction\n",
    "5. **Correlations**: Analyzed feature relationships to avoid redundancy\n",
    "\n",
    "### Next Steps:\n",
    "- Proceed to Task 2: Model Development (notebook 02_model_development.ipynb)\n",
    "- Train and evaluate multi-label classification models\n",
    "- Implement confidence scoring system"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
